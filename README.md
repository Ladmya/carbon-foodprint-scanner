# ğŸ« Carbon Foodprint Scanner

A comprehensive data engineering project that scans product barcodes and calculates carbon footprint transport equivalents. Built with Python 3.12, featuring a modular ETL pipeline and Telegram bot interface.

## ğŸŒŸ Features

- **ğŸ“± Telegram Bot Interface** - Scan barcodes and get carbon footprint data instantly
- **ğŸ” Barcode Scanning** - Real-time product identification using camera
- **ğŸ“Š Data Quality Analysis** - Comprehensive quality reports and missing data tracking
- **ğŸ—ï¸ Modular ETL Pipeline** - Separated Extract â†’ Transform â†’ Load architecture
- **ğŸ“ˆ Production Reports** - Executive summaries and business insights
- **ğŸ”§ Automated Setup** - One-command environment validation and setup

## ğŸš€ Quick Start

### 1. **Environment Setup**

```bash
# Clone the repository
git clone https://github.com/Ladmya/carbon-foodprint-scanner.git
cd carbon-foodprint-scanner

# Create and activate virtual environment
python -m venv carbon_foodprint-venv
source carbon_foodprint-venv/bin/activate  # On Windows: carbon_foodprint-venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Setup and validate environment
make setup
```

### 2. **Data Collection & Analysis**

```bash
# Collect data from OpenFoodFacts API
make collect

# Analyze data quality
make analyze-raw

# Generate production reports
make reports
```

### 3. **Launch the Telegram Bot**

```bash
# Start the bot interface
make run-bot
```

## ğŸ—ï¸ Architecture

### **Modular ETL Pipeline**
- **Extract**: `product_extractor_final.py` - Data extraction from OpenFoodFacts API
- **Transform**: `product_transformer_final.py` - Business rules and data validation
- **Load**: `load_products_to_supabase.py` - Database loading with error handling

### **Data Engineering Structure**
```
data_engineering/
â”œâ”€â”€ scripts/               # Operational scripts
â”‚   â”œâ”€â”€ setup/            # Environment setup and validation
â”‚   â”œâ”€â”€ collection/       # Data collection orchestrator
â”‚   â”œâ”€â”€ analysis/         # Data quality analysis
â”‚   â””â”€â”€ loading/          # Database loading
â”œâ”€â”€ data/                 # Data storage
â”‚   â”œâ”€â”€ raw/             # Raw data from APIs
â”‚   â”œâ”€â”€ processed/       # Validated and enriched data
â”‚   â”œâ”€â”€ analysis/        # Missing data tracking
â”‚   â””â”€â”€ reports/         # Production reports
â””â”€â”€ notebooks/           # Analysis notebooks
```

### **Core Application**
```
src/food_scanner/
â”œâ”€â”€ bot/                 # Telegram bot interface
â”œâ”€â”€ data/               # ETL pipeline components
â”œâ”€â”€ infrastructure/     # External APIs and database
â””â”€â”€ api/               # REST API (future)
```

## ğŸ“Š Data Quality & Reports

### **Quality Analysis**
- **Raw Data Quality**: `analyze_raw_data_quality.py` - Analyzes extraction quality
- **Missing Data Tracking**: Tracks missing CO2 data and critical fields
- **Production Reports**: Executive summaries and business insights

### **Report Structure**
```
data_engineering/data/reports/
â”œâ”€â”€ environment/         # Environment validation reports
â”œâ”€â”€ extraction/         # Raw data quality reports
â”œâ”€â”€ loading/           # Loading performance reports
â”œâ”€â”€ transformation/    # Transformed data quality reports
â”œâ”€â”€ quality/          # Overall quality reports
â””â”€â”€ production/       # Production readiness reports
```

## ğŸ”§ Available Commands

### **Data Operations**
```bash
make collect         # Run complete data collection pipeline
make analyze         # Run data quality analysis
make analyze-raw     # Analyze raw data quality specifically
make reports         # Generate production reports
make test-extraction # Test extraction component
make setup-data      # Setup data structure
make clean-data      # Clean cache and temporary files
```

### **Development**
```bash
make setup          # Validate environment
make setup-complete # Validate complete pipeline
make test           # Run tests (basic structure)
make test-unit      # Run unit tests (future)
make test-integration # Run integration tests (future)
make clean          # Clean temporary files
```

### **Bot Operations**
```bash
make run-bot        # Start Telegram bot
make test-bot       # Test bot functionality
```

## ğŸ› ï¸ Technical Stack

### **Current Stack**
- **Python 3.12** - Main language
- **python-telegram-bot** - Telegram bot interface
- **pyzbar** - Barcode scanning
- **Supabase** - PostgreSQL database
- **OpenFoodFacts API** - Product data source
- **Pillow & OpenCV** - Image processing
- **httpx** - HTTP client for APIs

### **Future Stack**
- **FastAPI** - REST API framework
- **SQLAlchemy** - ORM
- **Pydantic** - Data validation
- **Datadog** - Monitoring
- **pytest** - Comprehensive test suite

## ğŸ“ˆ Data Pipeline

1. **Extract**: Collect product data from OpenFoodFacts API
2. **Transform**: Apply business rules and validate data quality
3. **Load**: Store validated data in Supabase database
4. **Analyze**: Generate quality reports and insights
5. **Interface**: Provide Telegram bot for user interaction

## ğŸŒ Environment Variables

Create a `.env` file with the following variables:

```bash
# Telegram Bot
TELEGRAM_BOT_TOKEN=your_bot_token

# Supabase Database
SUPABASE_TEST_DATABASE_URL=your_test_db_url
SUPABASE_TEST_DATABASE_SERVICE_KEY=your_test_service_key
SUPABASE_PRODUCTION_DATABASE_URL=your_prod_db_url
SUPABASE_PRODUCTION_DATABASE_SERVICE_KEY=your_prod_service_key

# Environment
DB_ENVIRONMENT=test
USE_TEST_API=true
```

## ğŸ“ Weekly Workflow

1. **Setup**: `make setup` - Validate environment
2. **Collect**: `make collect` - Retrieve new products
3. **Analyze**: `make analyze-raw` - Check data quality
4. **Reports**: `make reports` - Generate insights
5. **Bot**: `make run-bot` - Launch user interface

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **OpenFoodFacts** - Product database and API
- **Supabase** - Database infrastructure
- **Python Telegram Bot** - Bot framework
- **pyzbar** - Barcode scanning library

---

**Built with â¤ï¸ for sustainable consumption awareness**

*Last updated: 2025-08-04*






